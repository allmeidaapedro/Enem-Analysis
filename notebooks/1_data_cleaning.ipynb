{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpeza dos microdados do ENEM 2022\n",
    "- Neste notebook, realizarei a limpeza dos microdados do ENEM 2022.\n",
    "- Os microdados se constituem no menor nível de desagregação de dados recolhidos por pesquisas, avaliações e exames realizados. No caso do ENEM, os dados estão por participante.\n",
    "- A limpeza de dados é necessária para performar a análise exploratória de dados. Dado o alto volume de dados e a sua origem (dados reais), algumas tarefas devem ser realizadas:\n",
    "    -  Identificação e tratamento de valores nulos e duplicados, de acordo com os objetivos da análise.\n",
    "    -  Remoção de variáveis irrelevantes para a análise.\n",
    "    -  Feature engineering: Criação e alteração de variáveis existentes. Aqui, irei fundir, remover e renomear categorias com base na melhor formatação para o meu objetivo. Além disso, converter colunas para o tipo de dado correto também será importante.\n",
    "    -  Otimização de memória: Conversão de variáveis a tipos de dados menores, a fim de melhorar a performance, possibilitando a leitura e manipulação dos dados em menor tempo, sem que haja a perda de informação.\n",
    "- Irei efetuar duas análises após a limpeza. O objetivo de cada uma delas guiará decisões tomadas futuramente neste notebook.\n",
    "- Na Análise de Desempenho, tenho como foco analisar o perfil de candidatos que obtêm determinadas notas, quais variáveis se relacionam com as notas e como estas poderiam ser utilizadas para predição. Portanto, é importante utilizar apenas dados de estudantes que estavam presentes em ambos os dias de prova, que de fato obtiveram um resultado. Incluir todos os alunos introduziria assimetrias e distorções na análise.\n",
    "- Na Análise de Abstenção, tenho como foco analisar quais os fatores que influenciam a ausência do candidato. Portanto, é necessário incluir todos os alunos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and visualization.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# File handling.\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Coletando os dados\n",
    "- Considerando o alto volume de dados, irei ler o dataset microdados em \"chunks\", partes menores, unindo tudo ao fim. Isso tornará a leitura mais eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading large data in separate chunks, then concatening into a single dataframe again.\n",
    "chunk_size = 50_000\n",
    "chunks = []\n",
    "microdados_path = \"D:\\MLProjects\\DadosENEM\\MICRODADOS_ENEM_2022.csv\"\n",
    "for chunk in pd.read_csv(microdados_path, sep=';', encoding='ISO-8859-1', chunksize=chunk_size):\n",
    "   chunks.append(chunk)\n",
    "\n",
    "microdados = pd.concat(chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Entendimento inicial dos dados e limpeza dos dados\n",
    "- Nesta etapa irei observar superficialmente os dados, obtendo dimensões, tipos de dados das variáveis, valores nulos e duplicados, estatísticas descritivas, entre outros.\n",
    "- Será realizada a limpeza deles também. Irei remover colunas desnecessárias, converter variáveis para os tipos de dado corretos, reduzir o tamanho do dataset, tratar valores nulos e outliers, entre outras tarefas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Dicionário de variáveis\n",
    "- O dicionário de variáveis encontra-se em 'input/dictionary/Dicionário_Microdados_ENEM_2022.xslx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Informações gerais sobre os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NU_INSCRICAO</th>\n",
       "      <th>NU_ANO</th>\n",
       "      <th>TP_FAIXA_ETARIA</th>\n",
       "      <th>TP_SEXO</th>\n",
       "      <th>TP_ESTADO_CIVIL</th>\n",
       "      <th>TP_COR_RACA</th>\n",
       "      <th>TP_NACIONALIDADE</th>\n",
       "      <th>TP_ST_CONCLUSAO</th>\n",
       "      <th>TP_ANO_CONCLUIU</th>\n",
       "      <th>TP_ESCOLA</th>\n",
       "      <th>...</th>\n",
       "      <th>Q016</th>\n",
       "      <th>Q017</th>\n",
       "      <th>Q018</th>\n",
       "      <th>Q019</th>\n",
       "      <th>Q020</th>\n",
       "      <th>Q021</th>\n",
       "      <th>Q022</th>\n",
       "      <th>Q023</th>\n",
       "      <th>Q024</th>\n",
       "      <th>Q025</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>210057943671</td>\n",
       "      <td>2022</td>\n",
       "      <td>14</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>210057516120</td>\n",
       "      <td>2022</td>\n",
       "      <td>14</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210057280536</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>210055724397</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>210055097896</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NU_INSCRICAO  NU_ANO  TP_FAIXA_ETARIA TP_SEXO  TP_ESTADO_CIVIL   \n",
       "0  210057943671    2022               14       M                2  \\\n",
       "1  210057516120    2022               14       M                2   \n",
       "2  210057280536    2022                5       F                1   \n",
       "3  210055724397    2022                6       M                1   \n",
       "4  210055097896    2022                4       M                0   \n",
       "\n",
       "   TP_COR_RACA  TP_NACIONALIDADE  TP_ST_CONCLUSAO  TP_ANO_CONCLUIU  TP_ESCOLA   \n",
       "0            2                 1                1                2          1  \\\n",
       "1            1                 1                1               16          1   \n",
       "2            2                 1                1                2          1   \n",
       "3            3                 1                1                2          1   \n",
       "4            3                 1                1                1          1   \n",
       "\n",
       "   ...  Q016  Q017  Q018 Q019  Q020 Q021  Q022  Q023  Q024  Q025  \n",
       "0  ...     B     A     A    A     A    A     A     A     A     A  \n",
       "1  ...     E     E     B    E     B    B     E     B     E     B  \n",
       "2  ...     A     A     A    A     A    A     C     A     A     B  \n",
       "3  ...     B     A     A    C     A    A     C     B     B     B  \n",
       "4  ...     A     A     A    A     A    A     B     A     A     A  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "microdados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3476105 entries, 0 to 3476104\n",
      "Data columns (total 76 columns):\n",
      " #   Column                  Dtype  \n",
      "---  ------                  -----  \n",
      " 0   NU_INSCRICAO            int64  \n",
      " 1   NU_ANO                  int64  \n",
      " 2   TP_FAIXA_ETARIA         int64  \n",
      " 3   TP_SEXO                 object \n",
      " 4   TP_ESTADO_CIVIL         int64  \n",
      " 5   TP_COR_RACA             int64  \n",
      " 6   TP_NACIONALIDADE        int64  \n",
      " 7   TP_ST_CONCLUSAO         int64  \n",
      " 8   TP_ANO_CONCLUIU         int64  \n",
      " 9   TP_ESCOLA               int64  \n",
      " 10  TP_ENSINO               float64\n",
      " 11  IN_TREINEIRO            int64  \n",
      " 12  CO_MUNICIPIO_ESC        float64\n",
      " 13  NO_MUNICIPIO_ESC        object \n",
      " 14  CO_UF_ESC               float64\n",
      " 15  SG_UF_ESC               object \n",
      " 16  TP_DEPENDENCIA_ADM_ESC  float64\n",
      " 17  TP_LOCALIZACAO_ESC      float64\n",
      " 18  TP_SIT_FUNC_ESC         float64\n",
      " 19  CO_MUNICIPIO_PROVA      int64  \n",
      " 20  NO_MUNICIPIO_PROVA      object \n",
      " 21  CO_UF_PROVA             int64  \n",
      " 22  SG_UF_PROVA             object \n",
      " 23  TP_PRESENCA_CN          int64  \n",
      " 24  TP_PRESENCA_CH          int64  \n",
      " 25  TP_PRESENCA_LC          int64  \n",
      " 26  TP_PRESENCA_MT          int64  \n",
      " 27  CO_PROVA_CN             float64\n",
      " 28  CO_PROVA_CH             float64\n",
      " 29  CO_PROVA_LC             float64\n",
      " 30  CO_PROVA_MT             float64\n",
      " 31  NU_NOTA_CN              float64\n",
      " 32  NU_NOTA_CH              float64\n",
      " 33  NU_NOTA_LC              float64\n",
      " 34  NU_NOTA_MT              float64\n",
      " 35  TX_RESPOSTAS_CN         object \n",
      " 36  TX_RESPOSTAS_CH         object \n",
      " 37  TX_RESPOSTAS_LC         object \n",
      " 38  TX_RESPOSTAS_MT         object \n",
      " 39  TP_LINGUA               int64  \n",
      " 40  TX_GABARITO_CN          object \n",
      " 41  TX_GABARITO_CH          object \n",
      " 42  TX_GABARITO_LC          object \n",
      " 43  TX_GABARITO_MT          object \n",
      " 44  TP_STATUS_REDACAO       float64\n",
      " 45  NU_NOTA_COMP1           float64\n",
      " 46  NU_NOTA_COMP2           float64\n",
      " 47  NU_NOTA_COMP3           float64\n",
      " 48  NU_NOTA_COMP4           float64\n",
      " 49  NU_NOTA_COMP5           float64\n",
      " 50  NU_NOTA_REDACAO         float64\n",
      " 51  Q001                    object \n",
      " 52  Q002                    object \n",
      " 53  Q003                    object \n",
      " 54  Q004                    object \n",
      " 55  Q005                    int64  \n",
      " 56  Q006                    object \n",
      " 57  Q007                    object \n",
      " 58  Q008                    object \n",
      " 59  Q009                    object \n",
      " 60  Q010                    object \n",
      " 61  Q011                    object \n",
      " 62  Q012                    object \n",
      " 63  Q013                    object \n",
      " 64  Q014                    object \n",
      " 65  Q015                    object \n",
      " 66  Q016                    object \n",
      " 67  Q017                    object \n",
      " 68  Q018                    object \n",
      " 69  Q019                    object \n",
      " 70  Q020                    object \n",
      " 71  Q021                    object \n",
      " 72  Q022                    object \n",
      " 73  Q023                    object \n",
      " 74  Q024                    object \n",
      " 75  Q025                    object \n",
      "dtypes: float64(21), int64(18), object(37)\n",
      "memory usage: 2.0+ GB\n"
     ]
    }
   ],
   "source": [
    "microdados.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O dataset possui 3476105 linhas e 76 colunas.\n"
     ]
    }
   ],
   "source": [
    "print(f'O dataset possui {microdados.shape[0]} linhas e {microdados.shape[1]} colunas.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Valores nulos e duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "microdados['NU_INSCRICAO'].duplicated().sum()\n",
    "microdados.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>null_pct</th>\n",
       "      <th>null_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TP_LOCALIZACAO_ESC</th>\n",
       "      <td>72.614636</td>\n",
       "      <td>2524161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO_UF_ESC</th>\n",
       "      <td>72.614636</td>\n",
       "      <td>2524161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP_SIT_FUNC_ESC</th>\n",
       "      <td>72.614636</td>\n",
       "      <td>2524161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP_DEPENDENCIA_ADM_ESC</th>\n",
       "      <td>72.614636</td>\n",
       "      <td>2524161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SG_UF_ESC</th>\n",
       "      <td>72.614636</td>\n",
       "      <td>2524161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO_MUNICIPIO_ESC</th>\n",
       "      <td>72.614636</td>\n",
       "      <td>2524161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NO_MUNICIPIO_ESC</th>\n",
       "      <td>72.614636</td>\n",
       "      <td>2524161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP_ENSINO</th>\n",
       "      <td>63.673594</td>\n",
       "      <td>2213361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NU_NOTA_CN</th>\n",
       "      <td>32.240396</td>\n",
       "      <td>1120710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO_PROVA_MT</th>\n",
       "      <td>32.240396</td>\n",
       "      <td>1120710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO_PROVA_CN</th>\n",
       "      <td>32.240396</td>\n",
       "      <td>1120710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX_RESPOSTAS_CN</th>\n",
       "      <td>32.240396</td>\n",
       "      <td>1120710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX_GABARITO_CN</th>\n",
       "      <td>32.240396</td>\n",
       "      <td>1120710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NU_NOTA_MT</th>\n",
       "      <td>32.240396</td>\n",
       "      <td>1120710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX_RESPOSTAS_MT</th>\n",
       "      <td>32.240396</td>\n",
       "      <td>1120710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX_GABARITO_MT</th>\n",
       "      <td>32.240396</td>\n",
       "      <td>1120710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP_STATUS_REDACAO</th>\n",
       "      <td>28.269083</td>\n",
       "      <td>982663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NU_NOTA_CH</th>\n",
       "      <td>28.269083</td>\n",
       "      <td>982663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NU_NOTA_REDACAO</th>\n",
       "      <td>28.269083</td>\n",
       "      <td>982663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO_PROVA_LC</th>\n",
       "      <td>28.269083</td>\n",
       "      <td>982663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO_PROVA_CH</th>\n",
       "      <td>28.269083</td>\n",
       "      <td>982663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NU_NOTA_COMP5</th>\n",
       "      <td>28.269083</td>\n",
       "      <td>982663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NU_NOTA_COMP4</th>\n",
       "      <td>28.269083</td>\n",
       "      <td>982663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX_RESPOSTAS_CH</th>\n",
       "      <td>28.269083</td>\n",
       "      <td>982663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX_RESPOSTAS_LC</th>\n",
       "      <td>28.269083</td>\n",
       "      <td>982663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NU_NOTA_COMP3</th>\n",
       "      <td>28.269083</td>\n",
       "      <td>982663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX_GABARITO_CH</th>\n",
       "      <td>28.269083</td>\n",
       "      <td>982663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX_GABARITO_LC</th>\n",
       "      <td>28.269083</td>\n",
       "      <td>982663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NU_NOTA_COMP2</th>\n",
       "      <td>28.269083</td>\n",
       "      <td>982663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NU_NOTA_COMP1</th>\n",
       "      <td>28.269083</td>\n",
       "      <td>982663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NU_NOTA_LC</th>\n",
       "      <td>28.269083</td>\n",
       "      <td>982663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q007</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q006</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q005</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q008</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         null_pct  null_count\n",
       "TP_LOCALIZACAO_ESC      72.614636     2524161\n",
       "CO_UF_ESC               72.614636     2524161\n",
       "TP_SIT_FUNC_ESC         72.614636     2524161\n",
       "TP_DEPENDENCIA_ADM_ESC  72.614636     2524161\n",
       "SG_UF_ESC               72.614636     2524161\n",
       "CO_MUNICIPIO_ESC        72.614636     2524161\n",
       "NO_MUNICIPIO_ESC        72.614636     2524161\n",
       "TP_ENSINO               63.673594     2213361\n",
       "NU_NOTA_CN              32.240396     1120710\n",
       "CO_PROVA_MT             32.240396     1120710\n",
       "CO_PROVA_CN             32.240396     1120710\n",
       "TX_RESPOSTAS_CN         32.240396     1120710\n",
       "TX_GABARITO_CN          32.240396     1120710\n",
       "NU_NOTA_MT              32.240396     1120710\n",
       "TX_RESPOSTAS_MT         32.240396     1120710\n",
       "TX_GABARITO_MT          32.240396     1120710\n",
       "TP_STATUS_REDACAO       28.269083      982663\n",
       "NU_NOTA_CH              28.269083      982663\n",
       "NU_NOTA_REDACAO         28.269083      982663\n",
       "CO_PROVA_LC             28.269083      982663\n",
       "CO_PROVA_CH             28.269083      982663\n",
       "NU_NOTA_COMP5           28.269083      982663\n",
       "NU_NOTA_COMP4           28.269083      982663\n",
       "TX_RESPOSTAS_CH         28.269083      982663\n",
       "TX_RESPOSTAS_LC         28.269083      982663\n",
       "NU_NOTA_COMP3           28.269083      982663\n",
       "TX_GABARITO_CH          28.269083      982663\n",
       "TX_GABARITO_LC          28.269083      982663\n",
       "NU_NOTA_COMP2           28.269083      982663\n",
       "NU_NOTA_COMP1           28.269083      982663\n",
       "NU_NOTA_LC              28.269083      982663\n",
       "Q007                     0.000000           0\n",
       "Q006                     0.000000           0\n",
       "Q005                     0.000000           0\n",
       "Q008                     0.000000           0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_df = (microdados.isna().sum() / len(microdados) * 100).to_frame().rename(columns={0: 'null_pct'})\n",
    "null_df['null_count'] = microdados.isna().sum()\n",
    "null_df.sort_values(by=['null_pct'], ascending=False).head(35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Não há observações duplicadas no dataset.\n",
    "- Variáveis referentes à escola possuem um alto percentual de nulos, acima de 70%, e portanto deverão ser removidas. \n",
    "- É possível ver um padrão nas variáveis referentes à nota e código de prova, possuindo o mesmo percentual de nulos para cada dia de aplicação (32% para as provas de ciências da natureza e matemática e 28.2% para as provas de ciências humanas, linguagens e suas tecnologias e redação). Provavelmente esses valores nulos representam alunos que não compareceram ou que foram eliminados, vamos investigar adiante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CO_PROVA_CN        1119133\n",
       "NU_NOTA_CN         1119133\n",
       "TX_RESPOSTAS_CN    1119133\n",
       "TX_GABARITO_CN     1119133\n",
       "CO_PROVA_MT        1119133\n",
       "NU_NOTA_MT         1119133\n",
       "TX_RESPOSTAS_MT    1119133\n",
       "TX_GABARITO_MT     1119133\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search for null values in the days when the student was not present for the second day of the exam.\n",
    "segundo_dia = ['CO_PROVA_CN',\n",
    " 'NU_NOTA_CN',\n",
    " 'TX_RESPOSTAS_CN',\n",
    " 'TX_GABARITO_CN',\n",
    " 'CO_PROVA_MT',\n",
    " 'NU_NOTA_MT',\n",
    " 'TX_RESPOSTAS_MT',\n",
    " 'TX_GABARITO_MT']\n",
    "microdados[segundo_dia].loc[(microdados['TP_PRESENCA_MT'] == 0) & (microdados['TP_PRESENCA_CN'] == 0)].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CO_PROVA_CN        1577\n",
       "NU_NOTA_CN         1577\n",
       "TX_RESPOSTAS_CN    1577\n",
       "TX_GABARITO_CN     1577\n",
       "CO_PROVA_MT        1577\n",
       "NU_NOTA_MT         1577\n",
       "TX_RESPOSTAS_MT    1577\n",
       "TX_GABARITO_MT     1577\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search for null values in the days when the student was eliminated for the second day of the exam.\n",
    "microdados[segundo_dia].loc[(microdados['TP_PRESENCA_MT'] == 2) & (microdados['TP_PRESENCA_CN'] == 2)].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CO_PROVA_CH          977981\n",
       "CO_PROVA_LC          977981\n",
       "NU_NOTA_CH           977981\n",
       "NU_NOTA_LC           977981\n",
       "TX_RESPOSTAS_CH      977981\n",
       "TX_RESPOSTAS_LC      977981\n",
       "TX_GABARITO_CH       977981\n",
       "TX_GABARITO_LC       977981\n",
       "TP_STATUS_REDACAO    977981\n",
       "NU_NOTA_COMP1        977981\n",
       "NU_NOTA_COMP2        977981\n",
       "NU_NOTA_COMP3        977981\n",
       "NU_NOTA_COMP4        977981\n",
       "NU_NOTA_COMP5        977981\n",
       "NU_NOTA_REDACAO      977981\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search for null values in the days when the student was not present for the first day of the exam.\n",
    "primeiro_dia = ['CO_PROVA_CH', 'CO_PROVA_LC', 'NU_NOTA_CH', 'NU_NOTA_LC',\n",
    "       'TX_RESPOSTAS_CH', 'TX_RESPOSTAS_LC', 'TX_GABARITO_CH',\n",
    "       'TX_GABARITO_LC', 'TP_STATUS_REDACAO', 'NU_NOTA_COMP1', 'NU_NOTA_COMP2',\n",
    "       'NU_NOTA_COMP3', 'NU_NOTA_COMP4', 'NU_NOTA_COMP5', 'NU_NOTA_REDACAO']\n",
    "microdados[primeiro_dia].loc[(microdados['TP_PRESENCA_CH'] == 0) & (microdados['TP_PRESENCA_LC'] == 0)].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CO_PROVA_CH          4682\n",
       "CO_PROVA_LC          4682\n",
       "NU_NOTA_CH           4682\n",
       "NU_NOTA_LC           4682\n",
       "TX_RESPOSTAS_CH      4682\n",
       "TX_RESPOSTAS_LC      4682\n",
       "TX_GABARITO_CH       4682\n",
       "TX_GABARITO_LC       4682\n",
       "TP_STATUS_REDACAO    4682\n",
       "NU_NOTA_COMP1        4682\n",
       "NU_NOTA_COMP2        4682\n",
       "NU_NOTA_COMP3        4682\n",
       "NU_NOTA_COMP4        4682\n",
       "NU_NOTA_COMP5        4682\n",
       "NU_NOTA_REDACAO      4682\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search for null values in the days when the student was eliminated for the first day of the exam.\n",
    "microdados[primeiro_dia].loc[(microdados['TP_PRESENCA_CH'] == 2) & (microdados['TP_PRESENCA_LC'] == 2)].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TP_PRESENCA_LC\n",
       "1    71.730917\n",
       "0    28.134392\n",
       "2     0.134691\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "microdados['TP_PRESENCA_LC'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TP_PRESENCA_MT\n",
       "1    67.759604\n",
       "0    32.195029\n",
       "2     0.045367\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "microdados['TP_PRESENCA_MT'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- É possível perceber que todas as observações que contêm valores nulos em variáveis contendo informações sobre as provas ocorrem por não comparecimento ou eliminação do estudante.\n",
    "- Considerando que variáveis contendo informações sobre o status da redacao, código da prova, gabaritos e respostas serão removidas porque não são relevantes para a análise, não imputarei valores nulos nelas.\n",
    "- Entre os principais objetivos da Análise de Desempenho, estão, entender o perfil dos candidatos que tiram determinadas notas, quais variáveis se relacionam com as notas e como estas podem ser utilizadas para predição. Portanto, candidatos faltantes que possuem notas nulas serão separados futuramente. Por enquanto, imputarei essas observações com nota zero. Isso será útil para analisar distribuições e fatores que influenciam o comparecimento (ou não) em cada dia de prova, compondo a Análise de Abstenção.\n",
    "- Para candidatos que foram eliminados, os quais também possuem nota nula nas provas, irei dropá-los de antemão, pois representam uma parcela muito pequena da população e não trazem informação relevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_microdados = microdados.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop eliminated records.\n",
    "eliminated_records = clean_microdados.loc[(clean_microdados['TP_PRESENCA_CN'] == 2) \n",
    "                                          | (clean_microdados['TP_PRESENCA_CH'] == 2) \n",
    "                                          | (microdados['TP_PRESENCA_LC'] == 2) \n",
    "                                          | (microdados['TP_PRESENCA_MT'] == 2)].index\n",
    "clean_microdados = clean_microdados.drop(eliminated_records)\n",
    "\n",
    "# Impute the grade as zero for those who didn't do the respective exam day.\n",
    "to_impute_grade = ['NU_NOTA_CN', 'NU_NOTA_MT', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_REDACAO', 'NU_NOTA_COMP1', 'NU_NOTA_COMP2', 'NU_NOTA_COMP3', 'NU_NOTA_COMP4', 'NU_NOTA_COMP5']\n",
    "clean_microdados[to_impute_grade] = clean_microdados[to_impute_grade].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Removendo colunas desnecessárias\n",
    "- É possível perceber que temos um grande número de colunas. Observando o dicionário de variáveis, muitas dessas não nos interessam, e portanto, serão removidas. Entram nesse grupo:\n",
    "    - Variáveis informando códigos (códigos de prova para cada área do conhecimento, de cidades, unidades federativas, entre outros).\n",
    "    - Variáveis que podem introduzir viés na análise, como as que identificam cor e raça.\n",
    "    - Variáveis com gabaritos e respostas de questões.\n",
    "    - Variáveis altamente desbalanceadas e que podem ser refletidas em valores de outras colunas, como o status da redação.\n",
    "    - Variáveis informando nacionalidade, número de inscrição e ano de conclusão do ensino médio. \n",
    "    - Variáveis com um identificador único para cada estudante.\n",
    "    - Variáveis contendo respostas para perguntas do questionário que não trazem valor para a análise ou que contêm múltiplas possibilidades para uma categoria.\n",
    "    - Variáveis com alto percentual de valores nulos, como visto acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3469856, 30)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining columns to drop.\n",
    "to_drop = ['NU_INSCRICAO', 'NU_ANO', 'TP_NACIONALIDADE', 'TP_COR_RACA', 'TP_ANO_CONCLUIU', \n",
    "           'CO_MUNICIPIO_ESC', 'NO_MUNICIPIO_ESC', 'CO_UF_ESC', 'SG_UF_ESC', 'TP_DEPENDENCIA_ADM_ESC', \n",
    "           'TP_LOCALIZACAO_ESC', 'TP_SIT_FUNC_ESC', 'TP_ENSINO', 'TP_STATUS_REDACAO', 'CO_MUNICIPIO_PROVA', 'CO_UF_PROVA', \n",
    "           'CO_PROVA_CN', 'CO_PROVA_CH', 'CO_PROVA_LC', 'CO_PROVA_MT', 'TX_RESPOSTAS_CN', 'TX_RESPOSTAS_CH', \n",
    "           'TX_RESPOSTAS_LC', 'TX_RESPOSTAS_MT', 'TX_GABARITO_CN', 'TX_GABARITO_CH', 'TX_GABARITO_LC', \n",
    "           'TX_GABARITO_MT', 'Q003', 'Q004', 'Q007', 'Q008', 'Q009', 'Q010', 'Q011', 'Q012', 'Q013', 'Q014', \n",
    "           'Q015', 'Q016', 'Q017', 'Q018', 'Q019', 'Q020', 'Q021', 'Q023']\n",
    "clean_microdados = clean_microdados.drop(columns=to_drop)\n",
    "clean_microdados.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ótimo! Já foi possível reduzir o número de variáveis de 76 para 30!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Alterando variáveis\n",
    "- De forma geral, variáveis de natureza categórica estão com tipos numéricos. Irei convertê-las com os respectivos valores categóricos a fim de tornar a análise interpretável e de fácil entendimento. Ao mesmo tempo em que converto, irei unir/dropar categorias, de acordo com o melhor critério.\n",
    "- Irei também padronizar os valores e renomear colunas para melhor entendimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardaze features names, formatting and renaming them.\n",
    "clean_microdados.columns = [x.lower() for x in clean_microdados.columns]\n",
    "\n",
    "prefixes_to_remove = ['tp_', 'in_', 'sg_', 'nu_', 'no_']\n",
    "clean_microdados.columns = clean_microdados.columns.to_series().replace(to_replace='^(' + '|'.join(prefixes_to_remove) + ')', value='', regex=True)\n",
    "\n",
    "to_rename = {'q001': 'escolaridade_pai', \n",
    "             'q002': 'escolaridade_mae',\n",
    "             'q003': 'ocupacao_pai',\n",
    "             'q004': 'ocupacao_mae',\n",
    "             'q005': 'numero_pessoas_em_casa',\n",
    "             'q006': 'renda_familiar_mensal',\n",
    "             'q022': 'possui_celular_em_casa',\n",
    "             'q024': 'possui_computador_em_casa',\n",
    "             'q025': 'acesso_internet_em_casa',\n",
    "             'st_conclusao': 'status_conclusao_ensino_medio'}\n",
    "\n",
    "clean_microdados = clean_microdados.rename(columns=to_rename)\n",
    "\n",
    "# Replace numeric values by categorical values in categorical features in numeric data type. \n",
    "# Merge similar age categories into one, and assigning them a categorical value for better analysis interpretation.\n",
    "faixa_etaria_mapping = {\n",
    "    'Adolescente (< 18)': [1, 2],                   # < 18\n",
    "    'Jovem adulto (18-24)': [3, 4, 5, 6, 7, 8, 9],  # 18-24\n",
    "    'Adulto jovem (25-35)': [10, 11, 12],           # 25-35\n",
    "    'Adulto de meia idade (36-45)': [13, 14],       # 36-45\n",
    "    'Meia idade (46-55)': [15, 16],                 # 46-55\n",
    "    'Pré aposentadoria (56-65)': [17, 18],          # 56-65\n",
    "    'Idoso (> 66)': [19, 20]                        # > 66\n",
    "}\n",
    "\n",
    "replaced_faixa_etaria = dict()\n",
    "\n",
    "for group, keys in faixa_etaria_mapping.items():\n",
    "    for key in keys:\n",
    "        replaced_faixa_etaria[key] = group\n",
    "\n",
    "clean_microdados['faixa_etaria'] = clean_microdados['faixa_etaria'].replace(to_replace=replaced_faixa_etaria)\n",
    "\n",
    "# Replace estado civil\n",
    "estado_civil_mapping = {\n",
    "    0: 'Não informado',\n",
    "    1: 'Solteiro(a)',\n",
    "    2: 'Casado(a)/União Estável',\n",
    "    3: 'Divorciado(a)/Separado(a)',\n",
    "    4: 'Viúvo(a)'\n",
    "}\n",
    "clean_microdados['estado_civil'] = clean_microdados['estado_civil'].replace(estado_civil_mapping)\n",
    "\n",
    "# Replace high school conclusion situation.\n",
    "st_conclusao_mapping = {\n",
    "    1: 'Concluído',\n",
    "    2: 'Último ano',\n",
    "    3: 'Cursando',\n",
    "    4: 'Não concluído'\n",
    "}\n",
    "clean_microdados['status_conclusao_ensino_medio'] = clean_microdados['status_conclusao_ensino_medio'].replace(st_conclusao_mapping)\n",
    "\n",
    "# Replace school type.\n",
    "escola_mapping = {\n",
    "    1: 'Não respondeu',\n",
    "    2: 'Pública',\n",
    "    3: 'Privada'\n",
    "}\n",
    "clean_microdados['escola'] = clean_microdados['escola'].replace(escola_mapping)\n",
    "\n",
    "# Replace presenca and lingua.\n",
    "clean_microdados[['presenca_cn', 'presenca_ch', 'presenca_lc', 'presenca_mt']] = clean_microdados[['presenca_cn', 'presenca_ch', 'presenca_lc', 'presenca_mt']].replace({1: 'Presente', 0: 'Ausente'})\n",
    "clean_microdados['lingua'] = clean_microdados['lingua'].replace({0: 'Inglês', 1: 'Espanhol'})\n",
    "\n",
    "# Replace questions answers.\n",
    "escolaridade_mapping = {\n",
    "    'A': 'Nunca estudou',\n",
    "    'B': 'Ensino fundamental incompleto',\n",
    "    'C': 'Ensino fundamental incompleto',\n",
    "    'D': 'Ensino fundamental completo',\n",
    "    'E': 'Ensino médio completo',\n",
    "    'F': 'Ensino superior completo',\n",
    "    'G': 'Pós-graduação',\n",
    "    'H': 'Não sei'\n",
    "}\n",
    "clean_microdados['escolaridade_pai'] = clean_microdados['escolaridade_pai'].replace(escolaridade_mapping)\n",
    "clean_microdados['escolaridade_mae'] = clean_microdados['escolaridade_mae'].replace(escolaridade_mapping)\n",
    "\n",
    "renda_mapping = {\n",
    "    'A': 'Nenhuma Renda',\n",
    "    'B': 'Até R$ 1.212,00',\n",
    "    'C': 'R$ 1.212,01 - R$ 1.818,00',\n",
    "    'D': 'R$ 1.818,01 - R$ 3.030,00',\n",
    "    'E': 'R$ 1.818,01 - R$ 3.030,00',\n",
    "    'F': 'R$ 3.030,01 - R$ 4.848,00',\n",
    "    'G': 'R$ 3.030,01 - R$ 4.848,00',\n",
    "    'H': 'R$ 4.848,01 - R$ 7.272,00',\n",
    "    'I': 'R$ 4.848,01 - R$ 7.272,00',\n",
    "    'J': 'R$ 7.272,01 - R$ 10.908,00',\n",
    "    'K': 'R$ 7.272,01 - R$ 10.908,00',\n",
    "    'L': 'R$ 7.272,01 - R$ 10.908,00',\n",
    "    'M': 'R$ 10.908,01 - R$ 18.180,00',\n",
    "    'N': 'R$ 10.908,01 - R$ 18.180,00',\n",
    "    'O': 'R$ 10.908,01 - R$ 18.180,00',\n",
    "    'P': 'R$ 18.180,01 - R$ 24.240,00',\n",
    "    'Q': 'Acima de R$ 24.240,00'\n",
    "}\n",
    "clean_microdados['renda_familiar_mensal'] = clean_microdados['renda_familiar_mensal'].replace(renda_mapping)\n",
    "\n",
    "computador_celular_mapping = {\n",
    "    'A': 'Não',\n",
    "    'B': 'Um',\n",
    "    'C': 'Dois ou mais',\n",
    "    'D': 'Dois ou mais',\n",
    "    'E': 'Dois ou mais'\n",
    "}\n",
    "clean_microdados['possui_celular_em_casa'] = clean_microdados['possui_celular_em_casa'].replace(computador_celular_mapping)\n",
    "clean_microdados['possui_computador_em_casa'] = clean_microdados['possui_computador_em_casa'].replace(computador_celular_mapping)\n",
    "\n",
    "internet_mapping = {\n",
    "    'A': 'Não', \n",
    "    'B': 'Sim'\n",
    "}\n",
    "clean_microdados['acesso_internet_em_casa'] = clean_microdados['acesso_internet_em_casa'].replace(internet_mapping)\n",
    "\n",
    "treineiro_mapping = {\n",
    "    0: 'Não',\n",
    "    1: 'Sim'\n",
    "}\n",
    "clean_microdados['treineiro'] = clean_microdados['treineiro'].replace(treineiro_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 Otimização de memória\n",
    "- Irei converter os tipos das variáveis para tipos que consomem menos memória sem perder informação, a fim de otimizar a análise e manipulação dos dados. \n",
    "- Após isso irei salvar o dataset resultante em um formato parquet, uma vez que o csv não mantém os tipos convertidos. \n",
    "- Uma vez que as notas vão de 0 a 1000 e têm precisão de 1 casa decimal, converterei-as de float64 para float32. Não será utilizado float16 pois o pyarrow não suporta esse tipo e não será possível salvar em parquet.\n",
    "- A única variável int é número_pessoas_em_casa. Esta será convertida de int64 para int8, sem perder informação, uma vez que ela guarda valores de 1 a 20. Através do tipo int8 podemos representar números de -128 a 127.\n",
    "- Variáveis com um número limitado de categorias exclusivas serão convertidas para category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain and convert columns to lower memory consumption data types.\n",
    "to_float32 = clean_microdados.select_dtypes('float64').columns.tolist()\n",
    "to_int8 = 'numero_pessoas_em_casa'\n",
    "to_category = clean_microdados.select_dtypes('object').columns.tolist()\n",
    "to_category.remove('municipio_prova')\n",
    "\n",
    "clean_df = clean_microdados.copy()\n",
    "clean_df[to_float32] = clean_df[to_float32].astype('float32')\n",
    "clean_df[to_category] = clean_df[to_category].astype('category')\n",
    "clean_df[to_int8] = clean_df[to_int8].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3469856 entries, 0 to 3476104\n",
      "Data columns (total 30 columns):\n",
      " #   Column                         Dtype   \n",
      "---  ------                         -----   \n",
      " 0   faixa_etaria                   category\n",
      " 1   sexo                           category\n",
      " 2   estado_civil                   category\n",
      " 3   status_conclusao_ensino_medio  category\n",
      " 4   escola                         category\n",
      " 5   treineiro                      category\n",
      " 6   municipio_prova                object  \n",
      " 7   uf_prova                       category\n",
      " 8   presenca_cn                    category\n",
      " 9   presenca_ch                    category\n",
      " 10  presenca_lc                    category\n",
      " 11  presenca_mt                    category\n",
      " 12  nota_cn                        float32 \n",
      " 13  nota_ch                        float32 \n",
      " 14  nota_lc                        float32 \n",
      " 15  nota_mt                        float32 \n",
      " 16  lingua                         category\n",
      " 17  nota_comp1                     float32 \n",
      " 18  nota_comp2                     float32 \n",
      " 19  nota_comp3                     float32 \n",
      " 20  nota_comp4                     float32 \n",
      " 21  nota_comp5                     float32 \n",
      " 22  nota_redacao                   float32 \n",
      " 23  escolaridade_pai               category\n",
      " 24  escolaridade_mae               category\n",
      " 25  numero_pessoas_em_casa         int8    \n",
      " 26  renda_familiar_mensal          category\n",
      " 27  possui_celular_em_casa         category\n",
      " 28  possui_computador_em_casa      category\n",
      " 29  acesso_internet_em_casa        category\n",
      "dtypes: category(18), float32(10), int8(1), object(1)\n",
      "memory usage: 248.2+ MB\n"
     ]
    }
   ],
   "source": [
    "clean_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>faixa_etaria</th>\n",
       "      <th>sexo</th>\n",
       "      <th>estado_civil</th>\n",
       "      <th>status_conclusao_ensino_medio</th>\n",
       "      <th>escola</th>\n",
       "      <th>treineiro</th>\n",
       "      <th>municipio_prova</th>\n",
       "      <th>uf_prova</th>\n",
       "      <th>presenca_cn</th>\n",
       "      <th>presenca_ch</th>\n",
       "      <th>...</th>\n",
       "      <th>nota_comp4</th>\n",
       "      <th>nota_comp5</th>\n",
       "      <th>nota_redacao</th>\n",
       "      <th>escolaridade_pai</th>\n",
       "      <th>escolaridade_mae</th>\n",
       "      <th>numero_pessoas_em_casa</th>\n",
       "      <th>renda_familiar_mensal</th>\n",
       "      <th>possui_celular_em_casa</th>\n",
       "      <th>possui_computador_em_casa</th>\n",
       "      <th>acesso_internet_em_casa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1317339</th>\n",
       "      <td>Jovem adulto (18-24)</td>\n",
       "      <td>F</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Último ano</td>\n",
       "      <td>Pública</td>\n",
       "      <td>Não</td>\n",
       "      <td>Silvânia</td>\n",
       "      <td>GO</td>\n",
       "      <td>Ausente</td>\n",
       "      <td>Presente</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Não sei</td>\n",
       "      <td>Ensino médio completo</td>\n",
       "      <td>5</td>\n",
       "      <td>R$ 1.212,01 - R$ 1.818,00</td>\n",
       "      <td>Dois ou mais</td>\n",
       "      <td>Não</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461840</th>\n",
       "      <td>Jovem adulto (18-24)</td>\n",
       "      <td>F</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Concluído</td>\n",
       "      <td>Não respondeu</td>\n",
       "      <td>Não</td>\n",
       "      <td>Vitória de Santo Antão</td>\n",
       "      <td>PE</td>\n",
       "      <td>Presente</td>\n",
       "      <td>Presente</td>\n",
       "      <td>...</td>\n",
       "      <td>140.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>Ensino fundamental incompleto</td>\n",
       "      <td>Ensino médio completo</td>\n",
       "      <td>5</td>\n",
       "      <td>Até R$ 1.212,00</td>\n",
       "      <td>Dois ou mais</td>\n",
       "      <td>Um</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2251916</th>\n",
       "      <td>Jovem adulto (18-24)</td>\n",
       "      <td>F</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Concluído</td>\n",
       "      <td>Não respondeu</td>\n",
       "      <td>Não</td>\n",
       "      <td>São Miguel do Oeste</td>\n",
       "      <td>SC</td>\n",
       "      <td>Presente</td>\n",
       "      <td>Presente</td>\n",
       "      <td>...</td>\n",
       "      <td>180.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>Ensino fundamental incompleto</td>\n",
       "      <td>Ensino fundamental completo</td>\n",
       "      <td>4</td>\n",
       "      <td>R$ 3.030,01 - R$ 4.848,00</td>\n",
       "      <td>Dois ou mais</td>\n",
       "      <td>Um</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041616</th>\n",
       "      <td>Adolescente (&lt; 18)</td>\n",
       "      <td>M</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Último ano</td>\n",
       "      <td>Pública</td>\n",
       "      <td>Não</td>\n",
       "      <td>Tianguá</td>\n",
       "      <td>CE</td>\n",
       "      <td>Ausente</td>\n",
       "      <td>Ausente</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ensino fundamental incompleto</td>\n",
       "      <td>Ensino fundamental incompleto</td>\n",
       "      <td>7</td>\n",
       "      <td>Nenhuma Renda</td>\n",
       "      <td>Um</td>\n",
       "      <td>Não</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691525</th>\n",
       "      <td>Jovem adulto (18-24)</td>\n",
       "      <td>M</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Último ano</td>\n",
       "      <td>Pública</td>\n",
       "      <td>Não</td>\n",
       "      <td>Guarulhos</td>\n",
       "      <td>SP</td>\n",
       "      <td>Ausente</td>\n",
       "      <td>Ausente</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ensino fundamental completo</td>\n",
       "      <td>Ensino fundamental completo</td>\n",
       "      <td>8</td>\n",
       "      <td>R$ 3.030,01 - R$ 4.848,00</td>\n",
       "      <td>Dois ou mais</td>\n",
       "      <td>Não</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 faixa_etaria sexo estado_civil status_conclusao_ensino_medio   \n",
       "1317339  Jovem adulto (18-24)    F  Solteiro(a)                    Último ano  \\\n",
       "1461840  Jovem adulto (18-24)    F  Solteiro(a)                     Concluído   \n",
       "2251916  Jovem adulto (18-24)    F  Solteiro(a)                     Concluído   \n",
       "2041616    Adolescente (< 18)    M  Solteiro(a)                    Último ano   \n",
       "1691525  Jovem adulto (18-24)    M  Solteiro(a)                    Último ano   \n",
       "\n",
       "                escola treineiro         municipio_prova uf_prova presenca_cn   \n",
       "1317339        Pública       Não                Silvânia       GO     Ausente  \\\n",
       "1461840  Não respondeu       Não  Vitória de Santo Antão       PE    Presente   \n",
       "2251916  Não respondeu       Não     São Miguel do Oeste       SC    Presente   \n",
       "2041616        Pública       Não                 Tianguá       CE     Ausente   \n",
       "1691525        Pública       Não               Guarulhos       SP     Ausente   \n",
       "\n",
       "        presenca_ch  ... nota_comp4 nota_comp5  nota_redacao   \n",
       "1317339    Presente  ...        0.0        0.0           0.0  \\\n",
       "1461840    Presente  ...      140.0      120.0         660.0   \n",
       "2251916    Presente  ...      180.0      140.0         760.0   \n",
       "2041616     Ausente  ...        0.0        0.0           0.0   \n",
       "1691525     Ausente  ...        0.0        0.0           0.0   \n",
       "\n",
       "                      escolaridade_pai               escolaridade_mae   \n",
       "1317339                        Não sei          Ensino médio completo  \\\n",
       "1461840  Ensino fundamental incompleto          Ensino médio completo   \n",
       "2251916  Ensino fundamental incompleto    Ensino fundamental completo   \n",
       "2041616  Ensino fundamental incompleto  Ensino fundamental incompleto   \n",
       "1691525    Ensino fundamental completo    Ensino fundamental completo   \n",
       "\n",
       "         numero_pessoas_em_casa      renda_familiar_mensal   \n",
       "1317339                       5  R$ 1.212,01 - R$ 1.818,00  \\\n",
       "1461840                       5            Até R$ 1.212,00   \n",
       "2251916                       4  R$ 3.030,01 - R$ 4.848,00   \n",
       "2041616                       7              Nenhuma Renda   \n",
       "1691525                       8  R$ 3.030,01 - R$ 4.848,00   \n",
       "\n",
       "         possui_celular_em_casa  possui_computador_em_casa   \n",
       "1317339            Dois ou mais                        Não  \\\n",
       "1461840            Dois ou mais                         Um   \n",
       "2251916            Dois ou mais                         Um   \n",
       "2041616                      Um                        Não   \n",
       "1691525            Dois ou mais                        Não   \n",
       "\n",
       "         acesso_internet_em_casa  \n",
       "1317339                      Sim  \n",
       "1461840                      Sim  \n",
       "2251916                      Sim  \n",
       "2041616                      Sim  \n",
       "1691525                      Sim  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the memory optimized data to a parquet file in order to maintain the converted data types.\n",
    "path = 'D:\\\\MLProjects\\\\EnemAnalysis\\\\input\\data\\\\clean_df.parquet'\n",
    "clean_df.to_parquet(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3469856 entries, 0 to 3469855\n",
      "Data columns (total 30 columns):\n",
      " #   Column                         Dtype   \n",
      "---  ------                         -----   \n",
      " 0   faixa_etaria                   category\n",
      " 1   sexo                           category\n",
      " 2   estado_civil                   category\n",
      " 3   status_conclusao_ensino_medio  category\n",
      " 4   escola                         category\n",
      " 5   treineiro                      category\n",
      " 6   municipio_prova                object  \n",
      " 7   uf_prova                       category\n",
      " 8   presenca_cn                    category\n",
      " 9   presenca_ch                    category\n",
      " 10  presenca_lc                    category\n",
      " 11  presenca_mt                    category\n",
      " 12  nota_cn                        float32 \n",
      " 13  nota_ch                        float32 \n",
      " 14  nota_lc                        float32 \n",
      " 15  nota_mt                        float32 \n",
      " 16  lingua                         category\n",
      " 17  nota_comp1                     float32 \n",
      " 18  nota_comp2                     float32 \n",
      " 19  nota_comp3                     float32 \n",
      " 20  nota_comp4                     float32 \n",
      " 21  nota_comp5                     float32 \n",
      " 22  nota_redacao                   float32 \n",
      " 23  escolaridade_pai               category\n",
      " 24  escolaridade_mae               category\n",
      " 25  numero_pessoas_em_casa         int8    \n",
      " 26  renda_familiar_mensal          category\n",
      " 27  possui_celular_em_casa         category\n",
      " 28  possui_computador_em_casa      category\n",
      " 29  acesso_internet_em_casa        category\n",
      "dtypes: category(18), float32(10), int8(1), object(1)\n",
      "memory usage: 221.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Read the memory optimized data.\n",
    "path = 'D:\\\\MLProjects\\\\EnemAnalysis\\\\input\\data\\\\clean_df.parquet'\n",
    "df = pd.read_parquet(path)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Conclusão\n",
    "- Excelente! Através da limpeza dos dados foi possível reduzir o tamanho do dataset de +2 GB para +221.7 MB, quase 10%! Agora poderemos realizar a análise e manipulação dos dados de forma eficiente.\n",
    "- Tarefas realizadas:\n",
    "    -  Identificação e tratamento de valores nulos e duplicados, de acordo com os objetivos da análise.\n",
    "    -  Remoção de variáveis irrelevantes para a análise.\n",
    "    -  Feature engineering: Criação e alteração de variáveis existentes. Aqui, irei fundir, remover e renomear categorias com base na melhor formatação para o meu objetivo. Além disso, converter colunas para o tipo de dado correto também será importante.\n",
    "    -  Otimização de memória: Conversão de variáveis a tipos de dados menores, a fim de melhorar a performance, possibilitando a leitura e manipulação dos dados em menor tempo, sem que haja a perda de informação."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
