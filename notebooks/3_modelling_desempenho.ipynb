{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previsão do desempenho (nota geral) do candidato\n",
    "- Neste notebook, será realizada uma tarefa de regressão, que consiste na previsão da nota geral do candidato (target) com base nas variáveis que vimos na análise exploratória de dados. Será aplicado o aprendizado supervisionado, com um conjunto de dados rotulado e um target contínuo.\n",
    "- O objetivo consiste em construir um modelo de machine learning capaz de prever acuradamente a nota geral do candidato. Além disso, avaliar quais variáveis independentes impactam mais e menos a nota.\n",
    "- Para isso, técnicas de limpeza e pré-processamento de dados (feature engineering), treinamento (seleção de features, comparação com validação cruzada, seleção, tunagem de hiperparâmetros) e validação de modelos de machine learning (avaliação de métricas em conjunto de testes) serão aplicadas.\n",
    "- Todo esse processo será baseado no framework CRISP-DM, podendo envolver ciclos de pré-processamento e validação de modelos repetidamente.\n",
    "- Pipeline de modelagem:\n",
    "    - Divisão dos dados em treino, teste e validação.\n",
    "    - Limpeza e pré-processamento dos dados.\n",
    "    - Comparação e seleção de modelo potencial com validação cruzada k-fold.\n",
    "    - Seleção de features.\n",
    "    - Tunagem de hiperparâmetros.\n",
    "    - Avaliação final no conjunto de testes (simulando o ambiente de produção).\n",
    "    - Deploy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and visualization.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modelling.\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import time\n",
    "import optuna\n",
    "import os\n",
    "import pickle\n",
    "from src.modelling_utils import *\n",
    "\n",
    "# Definições de cores -> todas estão numa escala de mais escura para mais clara.\n",
    "CINZA1, CINZA2, CINZA3 = '#231F20', '#414040', '#555655'\n",
    "CINZA4, CINZA5, CINZA6 = '#646369', '#76787B', '#828282'\n",
    "CINZA7, CINZA8, CINZA9 = '#929497', '#A6A6A5', '#BFBEBE'\n",
    "AZUL1, AZUL2, AZUL3, AZUL4 = '#174A7E', '#4A81BF', '#94B2D7', '#94AFC5'\n",
    "VERMELHO1, VERMELHO2, VERMELHO3, VERMELHO4, VERMELHO5 = '#DB0527', '#E23652', '#ED8293', '#F4B4BE', '#FBE6E9'\n",
    "VERDE1, VERDE2 = '#0C8040', '#9ABB59'\n",
    "LARANJA1 = '#F79747'\n",
    "AMARELO1, AMARELO2, AMARELO3, AMARELO4, AMARELO5 = '#FFC700', '#FFCC19', '#FFEB51', '#FFE37F', '#FFEEB2'\n",
    "BRANCO = '#FFFFFF'\n",
    "\n",
    "# Filter warnings.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Coletando os dados\n",
    "- Considerando que estamos tentando prever o desempenho do candidato na prova, serão incluídos na modelagem apenas dados de estudantes que compareceram em ambos os dias de prova, como visto na Análise de Desempenho no notebook '2_eda.ipynb'. Dessa forma, evitamos distorções e assimetrias, afinal, alunos que não comparecem ficam com nota nula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the memory optimized data.\n",
    "path = 'D:\\\\MLProjects\\\\DadosENEM\\\\clean_df.parquet'\n",
    "df = pd.read_parquet(path)\n",
    "\n",
    "# Selecting only students who were present in both the days of the exam.\n",
    "df = df.loc[(df['presenca_lc'] == 'Presente') & (df['presenca_ch'] == 'Presente') \n",
    "            & (df['presenca_cn'] == 'Presente') & (df['presenca_mt'] == 'Presente')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Rápida visualização e informações gerais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>faixa_etaria</th>\n",
       "      <th>sexo</th>\n",
       "      <th>estado_civil</th>\n",
       "      <th>status_conclusao_ensino_medio</th>\n",
       "      <th>escola</th>\n",
       "      <th>treineiro</th>\n",
       "      <th>municipio_prova</th>\n",
       "      <th>uf_prova</th>\n",
       "      <th>presenca_cn</th>\n",
       "      <th>presenca_ch</th>\n",
       "      <th>...</th>\n",
       "      <th>nota_comp3</th>\n",
       "      <th>nota_comp4</th>\n",
       "      <th>nota_comp5</th>\n",
       "      <th>nota_redacao</th>\n",
       "      <th>escolaridade_pai</th>\n",
       "      <th>escolaridade_mae</th>\n",
       "      <th>renda_familiar_mensal</th>\n",
       "      <th>possui_celular_em_casa</th>\n",
       "      <th>possui_computador_em_casa</th>\n",
       "      <th>acesso_internet_em_casa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jovem adulto (18-24)</td>\n",
       "      <td>F</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Concluído</td>\n",
       "      <td>Não respondeu</td>\n",
       "      <td>Não</td>\n",
       "      <td>Presidente Tancredo Neves</td>\n",
       "      <td>BA</td>\n",
       "      <td>Presente</td>\n",
       "      <td>Presente</td>\n",
       "      <td>...</td>\n",
       "      <td>120.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>Ensino médio completo</td>\n",
       "      <td>Ensino superior completo</td>\n",
       "      <td>Até R$ 1.212,00</td>\n",
       "      <td>Dois ou mais</td>\n",
       "      <td>Não</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jovem adulto (18-24)</td>\n",
       "      <td>M</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Concluído</td>\n",
       "      <td>Não respondeu</td>\n",
       "      <td>Não</td>\n",
       "      <td>Cariacica</td>\n",
       "      <td>ES</td>\n",
       "      <td>Presente</td>\n",
       "      <td>Presente</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>Ensino fundamental incompleto</td>\n",
       "      <td>Nunca estudou</td>\n",
       "      <td>Nenhuma Renda</td>\n",
       "      <td>Dois ou mais</td>\n",
       "      <td>Um</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jovem adulto (18-24)</td>\n",
       "      <td>F</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Concluído</td>\n",
       "      <td>Não respondeu</td>\n",
       "      <td>Não</td>\n",
       "      <td>São Gonçalo</td>\n",
       "      <td>RJ</td>\n",
       "      <td>Presente</td>\n",
       "      <td>Presente</td>\n",
       "      <td>...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>Ensino médio completo</td>\n",
       "      <td>Ensino médio completo</td>\n",
       "      <td>Até R$ 1.212,00</td>\n",
       "      <td>Dois ou mais</td>\n",
       "      <td>Não</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jovem adulto (18-24)</td>\n",
       "      <td>F</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Concluído</td>\n",
       "      <td>Não respondeu</td>\n",
       "      <td>Não</td>\n",
       "      <td>Arcoverde</td>\n",
       "      <td>PE</td>\n",
       "      <td>Presente</td>\n",
       "      <td>Presente</td>\n",
       "      <td>...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>Ensino médio completo</td>\n",
       "      <td>Ensino médio completo</td>\n",
       "      <td>Até R$ 1.212,00</td>\n",
       "      <td>Um</td>\n",
       "      <td>Não</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adolescente (&lt; 18)</td>\n",
       "      <td>F</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Último ano</td>\n",
       "      <td>Privada</td>\n",
       "      <td>Não</td>\n",
       "      <td>Nossa Senhora da Glória</td>\n",
       "      <td>SE</td>\n",
       "      <td>Presente</td>\n",
       "      <td>Presente</td>\n",
       "      <td>...</td>\n",
       "      <td>180.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>940.0</td>\n",
       "      <td>Ensino médio completo</td>\n",
       "      <td>Ensino médio completo</td>\n",
       "      <td>Até R$ 1.212,00</td>\n",
       "      <td>Dois ou mais</td>\n",
       "      <td>Não</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           faixa_etaria sexo estado_civil status_conclusao_ensino_medio   \n",
       "0  Jovem adulto (18-24)    F  Solteiro(a)                     Concluído  \\\n",
       "1  Jovem adulto (18-24)    M  Solteiro(a)                     Concluído   \n",
       "2  Jovem adulto (18-24)    F  Solteiro(a)                     Concluído   \n",
       "3  Jovem adulto (18-24)    F  Solteiro(a)                     Concluído   \n",
       "4    Adolescente (< 18)    F  Solteiro(a)                    Último ano   \n",
       "\n",
       "          escola treineiro            municipio_prova uf_prova presenca_cn   \n",
       "0  Não respondeu       Não  Presidente Tancredo Neves       BA    Presente  \\\n",
       "1  Não respondeu       Não                  Cariacica       ES    Presente   \n",
       "2  Não respondeu       Não                São Gonçalo       RJ    Presente   \n",
       "3  Não respondeu       Não                  Arcoverde       PE    Presente   \n",
       "4        Privada       Não    Nossa Senhora da Glória       SE    Presente   \n",
       "\n",
       "  presenca_ch  ... nota_comp3 nota_comp4  nota_comp5  nota_redacao   \n",
       "0    Presente  ...      120.0      140.0       160.0         760.0  \\\n",
       "1    Presente  ...       40.0      100.0        20.0         320.0   \n",
       "2    Presente  ...       80.0      100.0        40.0         440.0   \n",
       "3    Presente  ...       80.0       80.0        40.0         360.0   \n",
       "4    Presente  ...      180.0      200.0       200.0         940.0   \n",
       "\n",
       "                escolaridade_pai          escolaridade_mae   \n",
       "0          Ensino médio completo  Ensino superior completo  \\\n",
       "1  Ensino fundamental incompleto             Nunca estudou   \n",
       "2          Ensino médio completo     Ensino médio completo   \n",
       "3          Ensino médio completo     Ensino médio completo   \n",
       "4          Ensino médio completo     Ensino médio completo   \n",
       "\n",
       "  renda_familiar_mensal  possui_celular_em_casa  possui_computador_em_casa   \n",
       "0       Até R$ 1.212,00            Dois ou mais                        Não  \\\n",
       "1         Nenhuma Renda            Dois ou mais                         Um   \n",
       "2       Até R$ 1.212,00            Dois ou mais                        Não   \n",
       "3       Até R$ 1.212,00                      Um                        Não   \n",
       "4       Até R$ 1.212,00            Dois ou mais                        Não   \n",
       "\n",
       "   acesso_internet_em_casa  \n",
       "0                      Sim  \n",
       "1                      Sim  \n",
       "2                      Sim  \n",
       "3                      Sim  \n",
       "4                      Sim  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2344823 entries, 0 to 2344822\n",
      "Data columns (total 29 columns):\n",
      " #   Column                         Dtype   \n",
      "---  ------                         -----   \n",
      " 0   faixa_etaria                   category\n",
      " 1   sexo                           category\n",
      " 2   estado_civil                   category\n",
      " 3   status_conclusao_ensino_medio  category\n",
      " 4   escola                         category\n",
      " 5   treineiro                      category\n",
      " 6   municipio_prova                object  \n",
      " 7   uf_prova                       category\n",
      " 8   presenca_cn                    category\n",
      " 9   presenca_ch                    category\n",
      " 10  presenca_lc                    category\n",
      " 11  presenca_mt                    category\n",
      " 12  nota_cn                        float32 \n",
      " 13  nota_ch                        float32 \n",
      " 14  nota_lc                        float32 \n",
      " 15  nota_mt                        float32 \n",
      " 16  lingua                         category\n",
      " 17  nota_comp1                     float32 \n",
      " 18  nota_comp2                     float32 \n",
      " 19  nota_comp3                     float32 \n",
      " 20  nota_comp4                     float32 \n",
      " 21  nota_comp5                     float32 \n",
      " 22  nota_redacao                   float32 \n",
      " 23  escolaridade_pai               category\n",
      " 24  escolaridade_mae               category\n",
      " 25  renda_familiar_mensal          category\n",
      " 26  possui_celular_em_casa         category\n",
      " 27  possui_computador_em_casa      category\n",
      " 28  acesso_internet_em_casa        category\n",
      "dtypes: category(18), float32(10), object(1)\n",
      "memory usage: 147.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O dataset possui 2344823 linhas e 29 colunas.\n"
     ]
    }
   ],
   "source": [
    "print(f'O dataset possui {df.shape[0]} linhas e {df.shape[1]} colunas.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Valores nulos e duplicados\n",
    "- Valores nulos e duplicados, tipos de dados, entre outros processos já foram tratados no notebook '1_data_cleaning.ipynb'. Além disso, muitas variáveis irrelevantes já foram removidas. Iremos realizar daqui para frente, um refinamento com propósitos de modelagem, afinal, a limpeza inicial foi feita direcionada à análise exploratória de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "faixa_etaria                     0\n",
       "sexo                             0\n",
       "estado_civil                     0\n",
       "status_conclusao_ensino_medio    0\n",
       "escola                           0\n",
       "treineiro                        0\n",
       "municipio_prova                  0\n",
       "uf_prova                         0\n",
       "presenca_cn                      0\n",
       "presenca_ch                      0\n",
       "presenca_lc                      0\n",
       "presenca_mt                      0\n",
       "nota_cn                          0\n",
       "nota_ch                          0\n",
       "nota_lc                          0\n",
       "nota_mt                          0\n",
       "lingua                           0\n",
       "nota_comp1                       0\n",
       "nota_comp2                       0\n",
       "nota_comp3                       0\n",
       "nota_comp4                       0\n",
       "nota_comp5                       0\n",
       "nota_redacao                     0\n",
       "escolaridade_pai                 0\n",
       "escolaridade_mae                 0\n",
       "renda_familiar_mensal            0\n",
       "possui_celular_em_casa           0\n",
       "possui_computador_em_casa        0\n",
       "acesso_internet_em_casa          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Variáveis numéricas e categóricas\n",
    "- Irei verificar as variáveis numéricas e categóricas.\n",
    "- Isso influenciará a escolha de encoders e scalers futuramente na etapa de pré-processamento de dados. Cardinalidade é um fator importante a ser considerado.\n",
    "- Algumas variáveis podem ser transformadas de início. Por exemplo, variáveis binárias podem ter seus valores mapeados a 1 e 0.\n",
    "- Essas transformações antes do split não configuram data leakage pois são realizadas linha a linha.\n",
    "- Algumas variáveis podem ser removidas de início."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Há 19 variáveis categóricas. São elas: ['faixa_etaria', 'sexo', 'estado_civil', 'status_conclusao_ensino_medio', 'escola', 'treineiro', 'municipio_prova', 'uf_prova', 'presenca_cn', 'presenca_ch', 'presenca_lc', 'presenca_mt', 'lingua', 'escolaridade_pai', 'escolaridade_mae', 'renda_familiar_mensal', 'possui_celular_em_casa', 'possui_computador_em_casa', 'acesso_internet_em_casa']\n",
      "Há 10 variáveis numéricas. São elas: ['nota_cn', 'nota_ch', 'nota_lc', 'nota_mt', 'nota_comp1', 'nota_comp2', 'nota_comp3', 'nota_comp4', 'nota_comp5', 'nota_redacao']\n"
     ]
    }
   ],
   "source": [
    "categorical_features = df.select_dtypes(['category', 'object']).columns.to_list()\n",
    "numerical_features = df.select_dtypes('number').columns.to_list()\n",
    "print(f'Há {len(categorical_features)} variáveis categóricas. São elas: {categorical_features}')\n",
    "print(f'Há {len(numerical_features)} variáveis numéricas. São elas: {numerical_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cardinalidade das variáveis categóricas: \n",
      "faixa_etaria (7), sexo (2), estado_civil (5), status_conclusao_ensino_medio (4), escola (3), treineiro (2), municipio_prova (1712), uf_prova (27), presenca_cn (1), presenca_ch (1), presenca_lc (1), presenca_mt (1), lingua (2), escolaridade_pai (7), escolaridade_mae (7), renda_familiar_mensal (10), possui_celular_em_casa (3), possui_computador_em_casa (3), acesso_internet_em_casa (2), "
     ]
    }
   ],
   "source": [
    "print('Cardinalidade das variáveis categóricas: ')\n",
    "for feature in categorical_features:\n",
    "    print(f'{feature} ({df[feature].nunique()})', end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domínios das variáveis categóricas: \n",
      "\n",
      "faixa_etaria (faixa_etaria\n",
      "Jovem adulto (18-24)            53.912897\n",
      "Adolescente (< 18)              35.137066\n",
      "Adulto jovem (25-35)             7.054605\n",
      "Adulto de meia idade (36-45)     2.485774\n",
      "Meia idade (46-55)               1.051167\n",
      "Pré aposentadoria (56-65)        0.308723\n",
      "Idoso (> 66)                     0.049769\n",
      "Name: proportion, dtype: float64)\n",
      "\n",
      "sexo (sexo\n",
      "F    61.269785\n",
      "M    38.730215\n",
      "Name: proportion, dtype: float64)\n",
      "\n",
      "estado_civil (estado_civil\n",
      "Solteiro(a)                  92.323173\n",
      "Casado(a)/União Estável       3.337182\n",
      "Não informado                 3.115928\n",
      "Divorciado(a)/Separado(a)     1.145971\n",
      "Viúvo(a)                      0.077746\n",
      "Name: proportion, dtype: float64)\n",
      "\n",
      "status_conclusao_ensino_medio (status_conclusao_ensino_medio\n",
      "Concluído        41.074273\n",
      "Último ano       40.844490\n",
      "Cursando         17.786844\n",
      "Não concluído     0.294393\n",
      "Name: proportion, dtype: float64)\n",
      "\n",
      "escola (escola\n",
      "Não respondeu    59.155510\n",
      "Pública          32.448206\n",
      "Privada           8.396284\n",
      "Name: proportion, dtype: float64)\n",
      "\n",
      "treineiro (treineiro\n",
      "Não    82.213156\n",
      "Sim    17.786844\n",
      "Name: proportion, dtype: float64)\n",
      "\n",
      "municipio_prova (municipio_prova\n",
      "São Paulo              4.322757\n",
      "Rio de Janeiro         3.094349\n",
      "Fortaleza              2.049792\n",
      "Brasília               1.900868\n",
      "Belém                  1.766786\n",
      "                         ...   \n",
      "Santa Rosa do Purus    0.001365\n",
      "Jordão                 0.001322\n",
      "Barra do Turvo         0.001322\n",
      "Japurá                 0.000896\n",
      "Fernando de Noronha    0.000810\n",
      "Name: proportion, Length: 1712, dtype: float64)\n",
      "\n",
      "uf_prova (uf_prova\n",
      "SP    15.918131\n",
      "MG     9.145381\n",
      "BA     7.809118\n",
      "RJ     7.201141\n",
      "CE     6.669459\n",
      "PA     5.733695\n",
      "PE     5.559524\n",
      "RS     4.344550\n",
      "PR     4.266676\n",
      "MA     3.843915\n",
      "GO     3.831931\n",
      "PB     3.101471\n",
      "RN     2.644848\n",
      "PI     2.572049\n",
      "SC     2.383805\n",
      "DF     1.900868\n",
      "AL     1.851952\n",
      "ES     1.806831\n",
      "SE     1.792758\n",
      "AM     1.757873\n",
      "MT     1.590696\n",
      "MS     1.199280\n",
      "RO     0.835159\n",
      "TO     0.813537\n",
      "AC     0.609001\n",
      "AP     0.607807\n",
      "RR     0.208545\n",
      "Name: proportion, dtype: float64)\n",
      "\n",
      "presenca_cn (presenca_cn\n",
      "Presente    100.0\n",
      "Ausente       0.0\n",
      "Name: proportion, dtype: float64)\n",
      "\n",
      "presenca_ch (presenca_ch\n",
      "Presente    100.0\n",
      "Ausente       0.0\n",
      "Name: proportion, dtype: float64)\n",
      "\n",
      "presenca_lc (presenca_lc\n",
      "Presente    100.0\n",
      "Ausente       0.0\n",
      "Name: proportion, dtype: float64)\n",
      "\n",
      "presenca_mt (presenca_mt\n",
      "Presente    100.0\n",
      "Ausente       0.0\n",
      "Name: proportion, dtype: float64)\n",
      "\n",
      "lingua (lingua\n",
      "Inglês      57.898699\n",
      "Espanhol    42.101301\n",
      "Name: proportion, dtype: float64)\n",
      "\n",
      "escolaridade_pai (escolaridade_pai\n",
      "Ensino médio completo            30.744879\n",
      "Ensino fundamental incompleto    27.385564\n",
      "Ensino fundamental completo      11.074311\n",
      "Ensino superior completo         10.684815\n",
      "Não sei                           8.641889\n",
      "Pós-graduação                     8.233031\n",
      "Nunca estudou                     3.235511\n",
      "Name: proportion, dtype: float64)\n",
      "\n",
      "escolaridade_mae (escolaridade_mae\n",
      "Ensino médio completo            36.299627\n",
      "Ensino fundamental incompleto    20.080322\n",
      "Ensino superior completo         14.047286\n",
      "Pós-graduação                    13.758096\n",
      "Ensino fundamental completo      11.187795\n",
      "Não sei                           2.664849\n",
      "Nunca estudou                     1.962024\n",
      "Name: proportion, dtype: float64)\n",
      "\n",
      "renda_familiar_mensal (renda_familiar_mensal\n",
      "Até R$ 1.212,00                26.888682\n",
      "R$ 1.818,01 - R$ 3.030,00      20.100920\n",
      "R$ 1.212,01 - R$ 1.818,00      15.766819\n",
      "R$ 3.030,01 - R$ 4.848,00      11.131544\n",
      "R$ 4.848,01 - R$ 7.272,00       8.879561\n",
      "Nenhuma Renda                   5.086439\n",
      "R$ 7.272,01 - R$ 10.908,00      4.988436\n",
      "R$ 10.908,01 - R$ 18.180,00     4.243007\n",
      "Acima de R$ 24.240,00           1.665797\n",
      "R$ 18.180,01 - R$ 24.240,00     1.248794\n",
      "Name: proportion, dtype: float64)\n",
      "\n",
      "possui_celular_em_casa (possui_celular_em_casa\n",
      "Dois ou mais    83.548524\n",
      "Um              14.408934\n",
      "Não              2.042542\n",
      "Name: proportion, dtype: float64)\n",
      "\n",
      "possui_computador_em_casa (possui_computador_em_casa\n",
      "Não             42.158662\n",
      "Um              39.749482\n",
      "Dois ou mais    18.091856\n",
      "Name: proportion, dtype: float64)\n",
      "\n",
      "acesso_internet_em_casa (acesso_internet_em_casa\n",
      "Sim    91.958753\n",
      "Não     8.041247\n",
      "Name: proportion, dtype: float64)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Domínios das variáveis categóricas: ')\n",
    "print()\n",
    "for feature in categorical_features:\n",
    "    print(f'{feature} ({df[feature].value_counts(normalize=True) * 100})')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Possuem característica ordinal as variáveis: faixa_etaria, status_conclusao_ensino_medio, escolaridade_pai, escolaridade_mae, renda_familiar_mensal, possui_celular_em_casa e possui_computador_em_casa.\n",
    "- A variávei municipio_prova possui altíssima cardinalidade (1712 domínios distintos), não sendo relevante para a análise. Portanto, será removida.\n",
    "- Variáveis representando a presença ou ausência do candidato serão removidas, afinal, estamos lidando apenas com candidatos presentes e estas não só serão irrelevantes para a modelagem, bem como possuem variância constante.\n",
    "- Variáveis contendo a nota do candidato nas diferentes áreas do conhecimento, redação ou competências da redação serão removidas a fim de evitar data leakage. Não sabemos qual a nota do candidato em nada no ambiente de produção, isso é justamente o que queremos prever. Incluí-las criaria um cenário irreal, superestimando a performance do modelo.\n",
    "- A variável escola será removida pois possui 60% de nulos. Esses nulos representam alunos que não responderam qual o tipo de escola em que estudavam, por ser um campo opcional.\n",
    "- A variável estado civil será removida pois possui uma variância quase constante. Ela está altamente desbalanceada, com mais de 92% das observações pertencendo à categoria 'Solteiro(a)'. Além disso, mais de 3% estão como 'Não informado', constituindo valores nulos, dado que esse campo era opcional.\n",
    "- Serão removidas observações de estudantes que obtiveram nota 0, considerando a sua baixíssima frequência e considerando que estamos supondo que, uma vez presente, o aluno realizará a prova conforme é previsto. Ademais, isso permitirá que calculemos métricas como o MAPE.\n",
    "- A variável uf_prova também possui alta cardinalidade e será condensada em uma nova variável chamada \"região\". Essa nova variável manterá a informação e permitirá melhor aproveitamento pelo modelo, reduzindo a cardinalidade.\n",
    "- O nosso target será a nota geral, isto é, média das 5 provas (Linguagens, Ciências Humanas, Ciências da Natureza, Matemática e Redação). Iremos criar essa variável.\n",
    "- Serão mapeadas para binário ou ordinal as variáveis: acesso_internet_em_casa, possui_computador_em_casa, possui_celular_em_casa, lingua e treineiro.\n",
    "- Nas variáveis representando a escolaridade do pai e da mãe, há uma categoria \"Não sei\", indicando valores nulos. Esse valor nulo se deve provavelmente por esse ser um campo opcional do questionário socioeconômico, fazendo com que alguns estudantes pulem ele. Dito isso, podemos imputá-los ou removê-los. Eu irei imputá-los com o valor mais frequente, uma vez que esse domínio representa uma parte considerável dos nossos dados.\n",
    "- Variáveis como acesso_internet_em_casa e possui_celular_em_casa estão bastante desbalanceadas e serão avalidas na etapa de feature selection. Apesar de estarem desbalanceadas, foi visto na eda que elas apresentam distinção entre distribuições de notas obtidas pelos alunos. Talvez sejam importantes. \n",
    "- Considerando o significado geral parecido (responsável possui ensino superior), proporções parecidas, e pequena diferença de nota geral média observada na eda, irei combinar as categorias 'Ensino superior completo' e 'Pós-graduação' nas variáveis escolaridade_pai e escolaridade_mae. Isso poderá ajudar o modelo pois, claramente há uma distinção nas notas daqueles cujos pais graduaram-se.\n",
    "- Dadas as baixíssimas proporções e diferença mínima de nota geral média observada na eda, irei unir as categorias Pré aposentadoria (56-65) e Idoso (> 66), Adulto de meia idade (36-45) e Meia idade (46-55) na variável faixa_etaria. Isso reduz a cardinalidade e também poderá ajudar o modelo a não se confundir. O mesmo vale para as categorias Acima de R$ 24.240,00 e R$ 18.180,01 - R$ 24.240,00 na variável renda_familiar_mensal. O mesmo vale para a variável renda_familiar_mensal, que terá categorias combinadas a fim de reduzir o número de domínios distintos.\n",
    "- Estou combinando de forma mais conservadora dado que vi diferenças nas distribuições das notas mesmo para categorias de baixa proporção. Entretanto, serão testadas mais combinações no futuro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Limpeza de dados\n",
    "- Efetuarei os tópicos levantados acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a copy of the dataframe to procceed for data cleaning and next steps.\n",
    "clean_df = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a feature indicating the students' average grade.\n",
    "clean_df['nota_geral'] = (clean_df['nota_lc'] + clean_df['nota_ch'] + clean_df['nota_cn'] + clean_df['nota_mt'] + clean_df['nota_redacao']) / 5\n",
    "\n",
    "# Creating a feature indicating the region where the students' exams were applied.\n",
    "def define_regions(x):\n",
    "    if x in set(['RS', 'SC', 'PR']):\n",
    "        return 'Sul'\n",
    "    elif x in set(['SP', 'RJ', 'MG', 'ES']):\n",
    "        return 'Sudeste'\n",
    "    elif x in set(['AL', 'BA', 'CE', 'MA', 'PB', 'PE', 'PI', 'RN', 'SE']):\n",
    "        return 'Nordeste'\n",
    "    elif x in set(['AC', 'AM', 'AP', 'PA', 'RO', 'RR', 'TO']):\n",
    "        return 'Norte'\n",
    "    else:\n",
    "        return 'Centro-Oeste'\n",
    "\n",
    "clean_df['regiao'] = clean_df['uf_prova'].apply(define_regions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mapeamento para binário 1/0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping to binary or ordinal.\n",
    "clean_df['sexo'] = clean_df['sexo'].replace(to_replace={'M': 1, 'F': 0}).astype('int32')\n",
    "clean_df['lingua'] = clean_df['lingua'].replace(to_replace={'Inglês': 1, 'Espanhol': 0}).astype('int32')\n",
    "clean_df['treineiro'] = clean_df['treineiro'].replace(to_replace={'Sim': 1, 'Não': 0}).astype('int32')\n",
    "clean_df['acesso_internet_em_casa'] = clean_df['acesso_internet_em_casa'].replace(to_replace={'Sim': 1, 'Não': 0}).astype('int32')\n",
    "clean_df['possui_celular_em_casa'] = clean_df['possui_celular_em_casa'].replace(to_replace={'Dois ou mais': 2, 'Um': 1, 'Não': 0}).astype('int32')\n",
    "clean_df['possui_computador_em_casa'] = clean_df['possui_computador_em_casa'].replace(to_replace={'Dois ou mais': 2, 'Um': 1, 'Não': 0}).astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dropando variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2344823, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping irrelevant columns.\n",
    "to_drop = ['municipio_prova', 'presenca_cn', 'presenca_ch', \n",
    "       'presenca_lc', 'presenca_mt', 'nota_cn', 'nota_ch',\n",
    "       'nota_lc', 'nota_mt', 'lingua', 'nota_comp1', 'nota_comp2',\n",
    "       'nota_comp3', 'nota_comp4', 'nota_comp5', 'nota_redacao', \n",
    "       'escola', 'estado_civil', 'uf_prova']\n",
    "\n",
    "clean_df = clean_df.drop(columns=to_drop)\n",
    "clean_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['faixa_etaria',\n",
       " 'sexo',\n",
       " 'status_conclusao_ensino_medio',\n",
       " 'treineiro',\n",
       " 'escolaridade_pai',\n",
       " 'escolaridade_mae',\n",
       " 'renda_familiar_mensal',\n",
       " 'possui_celular_em_casa',\n",
       " 'possui_computador_em_casa',\n",
       " 'acesso_internet_em_casa',\n",
       " 'nota_geral',\n",
       " 'regiao']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assessing which are the remaining columns.\n",
    "clean_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Combinando categorias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "escolaridade_mae\n",
      "Ensino médio completo            36.299627\n",
      "Ensino superior completo         27.805382\n",
      "Ensino fundamental incompleto    20.080322\n",
      "Ensino fundamental completo      11.187795\n",
      "Não sei                           2.664849\n",
      "Nunca estudou                     1.962024\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "escolaridade_pai\n",
      "Ensino médio completo            30.744879\n",
      "Ensino fundamental incompleto    27.385564\n",
      "Ensino superior completo         18.917846\n",
      "Ensino fundamental completo      11.074311\n",
      "Não sei                           8.641889\n",
      "Nunca estudou                     3.235511\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "renda_familiar_mensal\n",
      "Renda baixa          42.655501\n",
      "Renda média baixa    31.232464\n",
      "Renda média alta     13.867998\n",
      "Renda alta            7.157598\n",
      "Nenhuma Renda         5.086439\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "faixa_etaria\n",
      "Jovem adulto (18-24)                53.912897\n",
      "Adolescente (< 18)                  35.137066\n",
      "Adulto jovem (25-35)                 7.054605\n",
      "Adulto a meia idade (36-55)          3.536941\n",
      "Pré aposentadoria a idoso (> 56)     0.358492\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Combining similar educational level categories.\n",
    "clean_df['escolaridade_mae'] = clean_df['escolaridade_mae'].replace(to_replace={'Pós-graduação': 'Ensino superior completo'})\n",
    "clean_df['escolaridade_pai'] = clean_df['escolaridade_pai'].replace(to_replace={'Pós-graduação': 'Ensino superior completo'})\n",
    "\n",
    "# Combining similar low proportion income categories.\n",
    "clean_df['renda_familiar_mensal'] = clean_df['renda_familiar_mensal'].replace(to_replace={\n",
    "    'Até R$ 1.212,00': 'Renda baixa',\n",
    "    'R$ 1.212,01 - R$ 1.818,00': 'Renda baixa',\n",
    "    'R$ 1.818,01 - R$ 3.030,00': 'Renda média baixa',\n",
    "    'R$ 3.030,01 - R$ 4.848,00': 'Renda média baixa',\n",
    "    'R$ 4.848,01 - R$ 7.272,00': 'Renda média alta',\n",
    "    'R$ 7.272,01 - R$ 10.908,00': 'Renda média alta', \n",
    "    'R$ 10.908,01 - R$ 18.180,00': 'Renda alta',\n",
    "    'R$ 18.180,01 - R$ 24.240,00': 'Renda alta',\n",
    "    'Acima de R$ 24.240,00': 'Renda alta'\n",
    "})\n",
    "\n",
    "# Combining similar low proportion age categories.\n",
    "clean_df['faixa_etaria'] = clean_df['faixa_etaria'].replace(to_replace={'Adulto de meia idade (36-45)': 'Adulto a meia idade (36-55)',\n",
    "                                                            'Meia idade (46-55)': 'Adulto a meia idade (36-55)',\n",
    "                                                            'Pré aposentadoria (56-65)': 'Pré aposentadoria a idoso (> 56)',\n",
    "                                                            'Idoso (> 66)': 'Pré aposentadoria a idoso (> 56)'})\n",
    "\n",
    "print(clean_df['escolaridade_mae'].value_counts(normalize=True)*100)\n",
    "print()\n",
    "print(clean_df['escolaridade_pai'].value_counts(normalize=True)*100)\n",
    "print()\n",
    "print(clean_df['renda_familiar_mensal'].value_counts(normalize=True)*100)\n",
    "print()\n",
    "print(clean_df['faixa_etaria'].value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Split dos dados em sets de treino, teste e validação\n",
    "- Os dados de teste são dados que o modelo nunca viu. Por isso, irei realizar o split antes de qualquer coisa. O teste será isolado e utilizado apenas no final para avaliar uma vez o melhor modelo escolhido. Isso garantirá uma avaliação de performance confiável, simulando um ambiente real de produção. Ademais, data leakage também é evitado, aplicando apenas 'transform' neste conjunto.\n",
    "- Os dados de validação serão utilizados na seleção de features e na tunagem de hiperparâmetros para avaliar o modelo treinado em cada configuração. Isso nos ajuda a prevenir o overfitting, evitando decisões baseadas em ajuste excessivo ao conjunto de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train predictor set shape: (1875858, 11). Train target set shape: (1875858,)\n",
      "Test predictor set shape: (234482, 11). Test target set shape: (234482,)\n",
      "Validation predictor set shape: (234483, 11). Validation target set shape: (234483,)\n"
     ]
    }
   ],
   "source": [
    "# Obtaining predictor and target sets.\n",
    "X = clean_df.drop(columns=['nota_geral'])\n",
    "y = clean_df['nota_geral'].copy()\n",
    "\n",
    "# Setting 80% training, 10% test and 10% validation.\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5)\n",
    "\n",
    "print(f'Train predictor set shape: {X_train.shape}. Train target set shape: {y_train.shape}')\n",
    "print(f'Test predictor set shape: {X_test.shape}. Test target set shape: {y_test.shape}')\n",
    "print(f'Validation predictor set shape: {X_val.shape}. Validation target set shape: {y_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Pré-processamento dos dados\n",
    "- Para treinar modelos de machine learning, é necessário aplicar algumas transformações aos dados:\n",
    "    - Imputar valores nulos: Há alguns valores nulos nas variáveis escolaridade_pai e escolaridade_mae, representados pela categoria 'Não sei'. Considerando que na escolaridade_pai estes representam uma parcela de 8% dos dados (alta), iremos imputá-los com a moda, e não removê-los.\n",
    "    - Outliers: Não há outliers.\n",
    "    - Para algoritmos baseados em árvore, não é necessário feature scaling. Entretanto, uma vez que eu desejo testar diferentes modelos, aplicarei feature scaling nas variáveis categóricas após sua codificação (não há variáveis numéricas). Assim será possível comparar todos os modelos de uma vez.\n",
    "    - Variáveis numéricas: Alguns algoritmos são sensíveis ao escalonamento de características, pois usam cálculos baseados em distância ou otimizações com gradiente descendente, por exemplo, sendo afetados pela escala. Considerando que não haverá outliers, dado que não há variáveis numéricas, apenas categóricas codificadas, aplicarei o StandardScaler. \n",
    "    - Variáveis categóricas: Algoritmos de machine learning efetuam cálculos matemáticos. Portanto, é necessário converter as variáveis categóricas para numéricas aplicando técnicas de encoding. As principais opções são target encoding, ordinal encoding, e one hot encoding. Uma observação importante é que one hot encoding pode ser prejudicial para modelos baseados em árvore, por conta da representação esparsa. Uma vez que já foram codificadas algumas features acima, será necessário apenas:\n",
    "        - Para regiao, utilizarei o OneHotEncoder pois há uma baixa cardinalidade, não resultando em grande aumento de dimensionalidade com as dummy variables. Além disso, essa variável não apresenta relação ordinal.\n",
    "        - Todas as outras variáveis possuem relação ordinal. Portanto, utilizarei o OrdinalEncoder. A fim de manter coerente a ordem após aplicar esta transformação (e não apenas por ordem alfabética, como faz a sklearn OrdinalEncoder) e integrá-la a um sklearn pipeline, será introduzido um ColumnTransformer dentro de um pipeline ordinal para conversão correta de cada variável, especificando as suas categorias na ordem correta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domínios das variáveis categóricas: \n",
      "\n",
      "faixa_etaria (['Jovem adulto (18-24)', 'Adolescente (< 18)', 'Adulto jovem (25-35)', 'Adulto a meia idade (36-55)', 'Pré aposentadoria a idoso (> 56)'])\n",
      "\n",
      "status_conclusao_ensino_medio (['Concluído', 'Último ano', 'Cursando', 'Não concluído'])\n",
      "\n",
      "escolaridade_pai (['Ensino médio completo', 'Ensino fundamental incompleto', 'Ensino superior completo', 'Não sei', 'Nunca estudou', 'Ensino fundamental completo'])\n",
      "\n",
      "escolaridade_mae (['Ensino superior completo', 'Nunca estudou', 'Ensino médio completo', 'Ensino fundamental completo', 'Ensino fundamental incompleto', 'Não sei'])\n",
      "\n",
      "renda_familiar_mensal (['Renda baixa', 'Nenhuma Renda', 'Renda média baixa', 'Renda média alta', 'Renda alta'])\n",
      "\n",
      "regiao (['Nordeste', 'Sudeste', 'Norte', 'Sul', 'Centro-Oeste'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assessing which are the remaining categorical features and its unique values.\n",
    "categorical_features = clean_df.select_dtypes(['category', 'object']).columns.to_list()\n",
    "print('Domínios das variáveis categóricas: ')\n",
    "print()\n",
    "for feature in categorical_features:\n",
    "    print(f'{feature} ({clean_df[feature].unique().tolist()})')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1875858, 15)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the features.\n",
    "ordinal_features = ['faixa_etaria', 'status_conclusao_ensino_medio', \n",
    "                    'escolaridade_pai', 'escolaridade_mae', \n",
    "                    'renda_familiar_mensal']\n",
    "nominal_features = ['regiao']\n",
    "\n",
    "# Imputing 'Não sei' with the mode.\n",
    "esc_mae_mode = X_train['escolaridade_mae'].mode()[0]\n",
    "esc_pai_mode = X_train['escolaridade_pai'].mode()[0]\n",
    "\n",
    "X_train['escolaridade_mae'] = X_train['escolaridade_mae'].replace(to_replace={'Não sei': esc_mae_mode})\n",
    "X_train['escolaridade_pai'] = X_train['escolaridade_pai'].replace(to_replace={'Não sei': esc_pai_mode})\n",
    "\n",
    "\n",
    "# Ordinal variables categories orders.\n",
    "age_categories_ordered = ['Adolescente (< 18)', 'Jovem adulto (18-24)',\n",
    "                           'Adulto jovem (25-35)', 'Adulto a meia idade (36-55)', \n",
    "                           'Pré aposentadoria a idoso (> 56)']\n",
    "status_categories_ordered = ['Não concluído', 'Cursando', \n",
    "                             'Último ano', 'Concluído']\n",
    "educational_level_categories_ordered = ['Nunca estudou', 'Ensino fundamental incompleto', \n",
    "                                        'Ensino fundamental completo', 'Ensino médio completo', \n",
    "                                        'Ensino superior completo']\n",
    "income_categories_ordered = ['Nenhuma Renda', 'Renda baixa', \n",
    "                             'Renda média baixa', 'Renda média alta',\n",
    "                             'Renda alta']\n",
    "\n",
    "# Ordinal encoding pipeline.\n",
    "ordinal_pipe = Pipeline([\n",
    "    ('ordinal_encoder', ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('age', OrdinalEncoder(categories=[age_categories_ordered]), ['faixa_etaria']),\n",
    "            ('status', OrdinalEncoder(categories=[status_categories_ordered]), ['status_conclusao_ensino_medio']),\n",
    "            ('dad', OrdinalEncoder(categories=[educational_level_categories_ordered]), ['escolaridade_pai']),\n",
    "            ('mom', OrdinalEncoder(categories=[educational_level_categories_ordered]), ['escolaridade_mae']),\n",
    "            ('income', OrdinalEncoder(categories=[income_categories_ordered]), ['renda_familiar_mensal'])\n",
    "        ]\n",
    "    )),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# One hot encoding pipeline.\n",
    "nominal_pipe = Pipeline([\n",
    "    ('one_hot_encoder', OneHotEncoder())\n",
    "])\n",
    "\n",
    "# Column transformer.\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('ordinal_encoding', ordinal_pipe, ordinal_features),\n",
    "        ('one_hot_encoding', nominal_pipe, nominal_features)\n",
    "    ], remainder='passthrough'\n",
    ")\n",
    "\n",
    "X_train_prepared = preprocessor.fit_transform(X_train, y_train)\n",
    "X_train_prepared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>faixa_etaria</th>\n",
       "      <th>status_conclusao_ensino_medio</th>\n",
       "      <th>escolaridade_pai</th>\n",
       "      <th>escolaridade_mae</th>\n",
       "      <th>renda_familiar_mensal</th>\n",
       "      <th>centro_oeste</th>\n",
       "      <th>nordeste</th>\n",
       "      <th>norte</th>\n",
       "      <th>sudeste</th>\n",
       "      <th>sul</th>\n",
       "      <th>sexo</th>\n",
       "      <th>treineiro</th>\n",
       "      <th>possui_celular_em_casa</th>\n",
       "      <th>possui_computador_em_casa</th>\n",
       "      <th>acesso_internet_em_casa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.267669</td>\n",
       "      <td>-0.306214</td>\n",
       "      <td>-1.227154</td>\n",
       "      <td>-0.623577</td>\n",
       "      <td>0.246896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.267669</td>\n",
       "      <td>1.043580</td>\n",
       "      <td>1.339806</td>\n",
       "      <td>1.142344</td>\n",
       "      <td>2.252699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.267669</td>\n",
       "      <td>-0.306214</td>\n",
       "      <td>-0.371501</td>\n",
       "      <td>0.259384</td>\n",
       "      <td>0.246896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.949940</td>\n",
       "      <td>1.043580</td>\n",
       "      <td>0.484152</td>\n",
       "      <td>-0.623577</td>\n",
       "      <td>-0.756005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.267669</td>\n",
       "      <td>1.043580</td>\n",
       "      <td>1.339806</td>\n",
       "      <td>0.259384</td>\n",
       "      <td>-0.756005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875853</th>\n",
       "      <td>2.949940</td>\n",
       "      <td>1.043580</td>\n",
       "      <td>1.339806</td>\n",
       "      <td>0.259384</td>\n",
       "      <td>0.246896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875854</th>\n",
       "      <td>0.267669</td>\n",
       "      <td>1.043580</td>\n",
       "      <td>-0.371501</td>\n",
       "      <td>-0.623577</td>\n",
       "      <td>-0.756005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875855</th>\n",
       "      <td>2.949940</td>\n",
       "      <td>1.043580</td>\n",
       "      <td>-1.227154</td>\n",
       "      <td>-2.389498</td>\n",
       "      <td>0.246896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875856</th>\n",
       "      <td>0.267669</td>\n",
       "      <td>1.043580</td>\n",
       "      <td>-1.227154</td>\n",
       "      <td>-1.506538</td>\n",
       "      <td>-0.756005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875857</th>\n",
       "      <td>-1.073467</td>\n",
       "      <td>-0.306214</td>\n",
       "      <td>0.484152</td>\n",
       "      <td>1.142344</td>\n",
       "      <td>2.252699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1875858 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         faixa_etaria  status_conclusao_ensino_medio  escolaridade_pai   \n",
       "0            0.267669                      -0.306214         -1.227154  \\\n",
       "1            0.267669                       1.043580          1.339806   \n",
       "2            0.267669                      -0.306214         -0.371501   \n",
       "3            2.949940                       1.043580          0.484152   \n",
       "4            0.267669                       1.043580          1.339806   \n",
       "...               ...                            ...               ...   \n",
       "1875853      2.949940                       1.043580          1.339806   \n",
       "1875854      0.267669                       1.043580         -0.371501   \n",
       "1875855      2.949940                       1.043580         -1.227154   \n",
       "1875856      0.267669                       1.043580         -1.227154   \n",
       "1875857     -1.073467                      -0.306214          0.484152   \n",
       "\n",
       "         escolaridade_mae  renda_familiar_mensal  centro_oeste  nordeste   \n",
       "0               -0.623577               0.246896           0.0       0.0  \\\n",
       "1                1.142344               2.252699           0.0       0.0   \n",
       "2                0.259384               0.246896           0.0       0.0   \n",
       "3               -0.623577              -0.756005           0.0       1.0   \n",
       "4                0.259384              -0.756005           0.0       1.0   \n",
       "...                   ...                    ...           ...       ...   \n",
       "1875853          0.259384               0.246896           0.0       0.0   \n",
       "1875854         -0.623577              -0.756005           0.0       1.0   \n",
       "1875855         -2.389498               0.246896           0.0       0.0   \n",
       "1875856         -1.506538              -0.756005           0.0       0.0   \n",
       "1875857          1.142344               2.252699           0.0       0.0   \n",
       "\n",
       "         norte  sudeste  sul  sexo  treineiro  possui_celular_em_casa   \n",
       "0          0.0      1.0  0.0   1.0        0.0                     2.0  \\\n",
       "1          0.0      1.0  0.0   0.0        0.0                     2.0   \n",
       "2          1.0      0.0  0.0   0.0        0.0                     2.0   \n",
       "3          0.0      0.0  0.0   0.0        0.0                     2.0   \n",
       "4          0.0      0.0  0.0   0.0        0.0                     2.0   \n",
       "...        ...      ...  ...   ...        ...                     ...   \n",
       "1875853    1.0      0.0  0.0   1.0        0.0                     2.0   \n",
       "1875854    0.0      0.0  0.0   0.0        0.0                     2.0   \n",
       "1875855    0.0      0.0  1.0   1.0        0.0                     2.0   \n",
       "1875856    1.0      0.0  0.0   0.0        0.0                     2.0   \n",
       "1875857    0.0      1.0  0.0   1.0        0.0                     1.0   \n",
       "\n",
       "         possui_computador_em_casa  acesso_internet_em_casa  \n",
       "0                              0.0                      1.0  \n",
       "1                              1.0                      1.0  \n",
       "2                              1.0                      1.0  \n",
       "3                              0.0                      1.0  \n",
       "4                              0.0                      1.0  \n",
       "...                            ...                      ...  \n",
       "1875853                        0.0                      1.0  \n",
       "1875854                        0.0                      1.0  \n",
       "1875855                        1.0                      1.0  \n",
       "1875856                        0.0                      1.0  \n",
       "1875857                        1.0                      1.0  \n",
       "\n",
       "[1875858 rows x 15 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtaining a dataframe of preprocessed data for further interpretation purposes, when analyzing feature importances, for example.\n",
    "cols = ['faixa_etaria', 'status_conclusao_ensino_medio', 'escolaridade_pai', 'escolaridade_mae', \n",
    "        'renda_familiar_mensal', 'centro_oeste', 'nordeste', 'norte', 'sudeste', 'sul', 'sexo', \n",
    "        'treineiro', 'possui_celular_em_casa', 'possui_computador_em_casa', 'acesso_internet_em_casa']\n",
    "X_train_prep_df = pd.DataFrame(X_train_prepared, columns=cols)\n",
    "X_train_prep_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Treinamento, comparação, seleção e tunagem de modelos\n",
    "- Nesta etapa, irei comparar a performance de diferentes modelos. Para isso, utilizarei a validação cruzada k-fold para treinar cada modelo, avaliando o seu RMSE.\n",
    "- O meu objetivo aqui é selecionar o(s) modelo(s) promissores, isto é, aqueles que apresentam o menor RMSE na validação cruzada, para seguir para as etapas de tunagem de hiperparâmetros e avaliação final no conjunto de testes, simulando o ambiente de produção.\n",
    "- O RMSE (Root Mean Square Error) é uma medida que representa a raiz quadrada da média dos quadrados das diferenças entre os valores previstos por um modelo e os valores reais. Ele nos informa o quanto as nossas predições desviam, em média, do valor real da nota geral.\n",
    "- Na validação cruzada k-fold, dividimos o conjunto de treinamento em k folds, avaliando em cada um dos k-ésimos folds um modelo treinado nos k-1 folds. Isso permitirá que eu obtenha uma medida robusta de como cada um performa, mitigando efeitos da variabilidade dos dados. Além disso, também será evitado o overfitting, uma vez que será possível, de antemão, observar como o modelo desempenha em dados nunca antes vistos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dicionário de modelos a serem avaliados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Linear SVR': LinearSVR(),\n",
    "    'SVR': SVR(),\n",
    "    'KNN': KNeighborsRegressor(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'LightGBM': LGBMRegressor(verbose=-1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Uma vez que a validação cruzada será utilizada para efeitos de comparação entre modelos e meus recursos computacionais são limitados, irei utilizar uma amostra de 100,000 linhas do conjunto de dados. Esse volume permitirá uma boa generalização dos modelos.\n",
    "- Aplicarei a amostragem aleatória simples, obtendo um subconjunto representativo. Além disso, dada a propriedade da validação cruzada de mitigar efeitos da variabilidade nos dados, esta é uma ótima estratégia para operar em um dataset desse tamanho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000, 15), (100000,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtaining a simple random sample of 100,000 records from the original data for computational efficiency purposes.\n",
    "sample_size = 100_000\n",
    "X_train_sample = X_train.sample(sample_size)\n",
    "y_train_sample = y_train.sample(sample_size)\n",
    "\n",
    "# Preprocessing my sample.\n",
    "X_train_sample_prep = preprocessor.fit_transform(X_train_sample)\n",
    "X_train_sample_prep.shape, y_train_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Validação cruzada k-fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression results: \n",
      "--------------------------------------------------\n",
      "Training score: 87.75784679805699\n",
      "Average validation score: 87.77116147182264\n",
      "Standard deviation: 0.25956386362283596\n",
      "Training time: 0.31801 seconds\n",
      "\n",
      "Linear SVR results: \n",
      "--------------------------------------------------\n",
      "Training score: 87.87530403033094\n",
      "Average validation score: 87.90356459304051\n",
      "Standard deviation: 0.253156971597355\n",
      "Training time: 0.1967 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_df = evaluate_models_cv(models=models, \n",
    "                             X_train=X_train_sample_prep, \n",
    "                             y_train=y_train_sample)\n",
    "eval_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
